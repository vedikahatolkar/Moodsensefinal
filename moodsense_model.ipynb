{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedikahatolkar/Moodsensefinal/blob/main/moodsense_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qRzSqs8X9cO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Audio + DSP packages\n",
        "!pip install sounddevice scipy\n",
        "\n",
        "# Core transformers stack (compatible with Py3.12)\n",
        "!pip install --upgrade transformers datasets accelerate safetensors tokenizers\n",
        "\n",
        "# ML packages\n",
        "!pip install scikit-learn librosa soundfile matplotlib tensorflow keras\n",
        "\n",
        "# SentencePiece (working version for Py3.12)\n",
        "!pip install sentencepiece==0.1.99\n",
        "\n",
        "# Upgrade build tools\n",
        "!python -m pip install --upgrade pip setuptools wheel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B604B269YdyU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import librosa\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5DW0OMFYgJu"
      },
      "outputs": [],
      "source": [
        "print(\"Loading GoEmotions...\")\n",
        "raw = load_dataset(\"go_emotions\")\n",
        "\n",
        "map_dict = {\n",
        "    'admiration':'happy','amusement':'happy','joy':'happy','love':'happy','optimism':'happy','approval':'happy',\n",
        "    'sadness':'sad','disappointment':'sad','grief':'sad',\n",
        "    'anger':'angry','annoyance':'angry','disgust':'angry',\n",
        "    'fear':'fear','nervousness':'fear',\n",
        "}\n",
        "\n",
        "label_names = raw['train'].features['labels'].feature.names\n",
        "\n",
        "def map_emotion(example):\n",
        "    labels = [label_names[i] for i in example['labels']]\n",
        "    mapped = [map_dict.get(l, 'neutral') for l in labels]\n",
        "    example[\"emotion\"] = mapped[0] if mapped else \"neutral\"\n",
        "    return example\n",
        "\n",
        "raw = raw.map(map_emotion)\n",
        "raw = raw.remove_columns([\"id\",\"labels\"])\n",
        "raw[\"train\"][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7apSt_HkYoEU"
      },
      "outputs": [],
      "source": [
        "MODEL_TEXT = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_TEXT)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "proc = raw.map(tokenize, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w280wo0JY4Wn"
      },
      "outputs": [],
      "source": [
        "unique_emotions = list(sorted(set(proc[\"train\"][\"emotion\"])))\n",
        "label2id = {e:i for i,e in enumerate(unique_emotions)}\n",
        "id2label = {i:e for e,i in label2id.items()}\n",
        "\n",
        "def encode_labels(example):\n",
        "    example[\"labels\"] = label2id[example[\"emotion\"]]\n",
        "    return example\n",
        "\n",
        "proc = proc.map(encode_labels)\n",
        "proc = proc.remove_columns([\"emotion\"])\n",
        "proc.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
        "\n",
        "label2id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJJlVMm3Y97X"
      },
      "outputs": [],
      "source": [
        "model_text = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_TEXT,\n",
        "    num_labels=len(label2id),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5rOof-kZAnY"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert_emotion_model\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=3e-5,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    do_eval=True,\n",
        "    eval_strategy=\"steps\",   # works on all versions\n",
        "    save_strategy=\"steps\",         # works on all versions\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        "    logging_steps=200\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU3ZHZ6BHGNe"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convert HuggingFace 'proc[\"train\"]' to list for sklearn split\n",
        "texts = proc[\"train\"][\"input_ids\"]\n",
        "masks = proc[\"train\"][\"attention_mask\"]\n",
        "labels = proc[\"train\"][\"labels\"]\n",
        "\n",
        "# Split 80/20\n",
        "train_idx, test_idx = train_test_split(\n",
        "    range(len(texts)),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Build new HF DatasetDict\n",
        "train_dataset = proc[\"train\"].select(train_idx)\n",
        "test_dataset = proc[\"train\"].select(test_idx)\n",
        "\n",
        "new_data = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"test\": test_dataset\n",
        "})\n",
        "\n",
        "print(new_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvABk5cRZDoS"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model_text,\n",
        "    args=training_args,\n",
        "    train_dataset=new_data[\"train\"],   # 80% training\n",
        "    eval_dataset=new_data[\"test\"]      # 20% testing\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(\"./bert_emotion_model\")\n",
        "print(\"Model training complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6XegXHRhK6E"
      },
      "outputs": [],
      "source": [
        "def predict_text_emotion(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    inputs = {key: value.to(model_text.device) for key, value in inputs.items()} # Move inputs to model's device\n",
        "    with torch.no_grad():\n",
        "        outputs = model_text(**inputs)\n",
        "    probs = torch.softmax(outputs.logits, dim=1)\n",
        "    pred = torch.argmax(probs).item()\n",
        "    return id2label[pred]\n",
        "\n",
        "print(predict_text_emotion(\"I am feeling very sad today\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk5U-7OgiBqP"
      },
      "outputs": [],
      "source": [
        "def extract_mfcc(file, max_len=200):\n",
        "    y, sr = librosa.load(file, sr=22050)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
        "    if mfcc.shape[1] < max_len:\n",
        "        mfcc = np.pad(mfcc, ((0,0),(0, max_len - mfcc.shape[1])), mode=\"constant\")\n",
        "    else:\n",
        "        mfcc = mfcc[:, :max_len]\n",
        "    return mfcc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-CKGCPhiIs4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "\n",
        "def build_cnn():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3,3), activation=\"relu\", input_shape=(40,200,1)),\n",
        "        MaxPool2D((2,2)),\n",
        "        Conv2D(64, (3,3), activation=\"relu\"),\n",
        "        MaxPool2D((2,2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dropout(0.3),\n",
        "        Dense(5, activation=\"softmax\")\n",
        "    ])\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "model_speech = build_cnn()\n",
        "model_speech.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tg-TASGxiSkF"
      },
      "outputs": [],
      "source": [
        "def predict_speech_emotion(file):\n",
        "    mfcc = extract_mfcc(file)\n",
        "    x = mfcc.reshape(1,40,200,1)\n",
        "    pred = model_speech.predict(x)[0]\n",
        "    classes = [\"angry\",\"happy\",\"sad\",\"fear\",\"neutral\"]\n",
        "    return classes[np.argmax(pred)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0BUp_72ipMp"
      },
      "outputs": [],
      "source": [
        "def chatbot_respond(text, emotion):\n",
        "    responses = {\n",
        "        \"happy\": \"I'm glad to hear that! What made you feel happy today?\",\n",
        "        \"sad\": \"I'm sorry you're feeling sad. I'm here for you â€” want to talk about it?\",\n",
        "        \"angry\": \"It sounds frustrating. What made you feel this way?\",\n",
        "        \"fear\": \"It's okay to feel anxious. Do you want to share what's worrying you?\",\n",
        "        \"neutral\": \"Thanks for sharing. How are you feeling overall?\"\n",
        "    }\n",
        "    return responses.get(emotion, responses[\"neutral\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTRKDPJait8f"
      },
      "outputs": [],
      "source": [
        "def moodsense(text, audio_file=None):\n",
        "    text_em = predict_text_emotion(text)\n",
        "    audio_em = None # Initialize audio_em\n",
        "\n",
        "    if audio_file:\n",
        "        try:\n",
        "            audio_em = predict_speech_emotion(audio_file)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing audio: {e}\")\n",
        "            audio_em = None # Ensure audio_em is None if there's an error\n",
        "\n",
        "    if audio_em is None:\n",
        "        final_em = text_em\n",
        "    elif audio_em == \"neutral\":\n",
        "        final_em = text_em # text gets priority if audio is neutral\n",
        "    else:\n",
        "        final_em = audio_em # Use audio emotion if available and not neutral\n",
        "\n",
        "    reply = chatbot_respond(text, final_em)\n",
        "\n",
        "    print(\"Text Emotion:\", text_em)\n",
        "    print(\"Audio Emotion:\", audio_em)\n",
        "    print(\"Final Decision:\", final_em)\n",
        "    print(\"\\nChatbot Response:\\n\", reply)\n",
        "\n",
        "    return final_em, reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d4264b6"
      },
      "outputs": [],
      "source": [
        "moodsense(\"I am feeling really excited about this project!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARLxDjGolBTY"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "import base64\n",
        "from IPython.display import Audio\n",
        "\n",
        "def record_audio():\n",
        "    js = \"\"\"\n",
        "    async function record() {\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({audio: true});\n",
        "      const recorder = new MediaRecorder(stream);\n",
        "      let chunks = [];\n",
        "\n",
        "      recorder.ondataavailable = e => chunks.push(e.data);\n",
        "      recorder.onstop = e => {\n",
        "        let blob = new Blob(chunks, {type: 'audio/wav'});\n",
        "        let reader = new FileReader();\n",
        "        reader.readAsDataURL(blob);\n",
        "        reader.onloadend = () => {\n",
        "          google.colab.kernel.invokeFunction('notebook.saveAudio', [reader.result], {});\n",
        "        };\n",
        "      };\n",
        "\n",
        "      recorder.start();\n",
        "      await new Promise(resolve => setTimeout(resolve, 5000));\n",
        "      recorder.stop();\n",
        "    }\n",
        "    record();\n",
        "    \"\"\"\n",
        "    output.eval_js(js)\n",
        "\n",
        "audio_bytes = None\n",
        "\n",
        "def save_audio(data):\n",
        "    global audio_bytes\n",
        "    audio_bytes = base64.b64decode(data.split(',')[1])\n",
        "\n",
        "output.register_callback('notebook.saveAudio', save_audio)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5DYyb64lJPw"
      },
      "outputs": [],
      "source": [
        "print(\"ðŸŽ¤ Recording for 5 seconds...\")\n",
        "record_audio()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlKim1zClc_A"
      },
      "outputs": [],
      "source": [
        "if audio_bytes:\n",
        "    with open(\"mic_input.wav\", \"wb\") as f:\n",
        "        f.write(audio_bytes)\n",
        "    print(\"Audio saved as mic_input.wav\")\n",
        "\n",
        "Audio(\"mic_input.wav\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qWZuq5Clo-Y"
      },
      "outputs": [],
      "source": [
        "moodsense(\"Here is my spoken input\", \"mic_input.wav\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r bert_emotion_model.zip bert_emotion_model"
      ],
      "metadata": {
        "id": "GzRc5mZWNrJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"bert_emotion_model.zip\")"
      ],
      "metadata": {
        "id": "QKKHpi9sNx9r",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}